{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "collapsed_sections": [
        "823MdBUFNY-I"
      ],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/PenditWiguna/Capstone/blob/main/Machine%20Learning/Notebook/Content%20Based%20Model.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "\n",
        "# Memuat data CSV\n",
        "data = pd.read_csv('https://raw.githubusercontent.com/PenditWiguna/Capstone/main/Machine%20Learning/Dataset/Dataset%20-%20tourismBali.csv')\n",
        "\n",
        "# Memisahkan data\n",
        "df = data[['Place_Id', 'Description', 'Category']]\n",
        "\n",
        "# Encode kategori\n",
        "category_encoder = LabelEncoder()\n",
        "df['Category_Encoded'] = category_encoder.fit_transform(df['Category'])\n",
        "\n",
        "# Tokenisasi dan padding deskripsi\n",
        "tokenizer = Tokenizer()\n",
        "tokenizer.fit_on_texts(df['Description'])\n",
        "sequences = tokenizer.texts_to_sequences(df['Description'])\n",
        "padded_sequences = pad_sequences(sequences, padding='post')\n",
        "\n",
        "# Tentukan panjang maksimal sequence\n",
        "max_sequence_length = padded_sequences.shape[1]\n",
        "\n",
        "# Data input untuk model\n",
        "X_category = df['Category_Encoded'].values\n",
        "X_description = padded_sequences\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z-7-Bz5cYvfK",
        "outputId": "7fa1680a-4ff2-4027-855e-f7b44511e290"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-1-9ae1abcdf1e2>:16: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  df['Category_Encoded'] = category_encoder.fit_transform(df['Category'])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Tentukan ukuran embedding\n",
        "embedding_dim = 50\n",
        "vocab_size = len(tokenizer.word_index) + 1\n",
        "category_count = len(df['Category_Encoded'].unique())\n",
        "\n",
        "# Input kategori\n",
        "category_input = tf.keras.layers.Input(shape=(1,), name='category_input')\n",
        "category_embedding = tf.keras.layers.Embedding(input_dim=category_count, output_dim=embedding_dim, name='category_embedding')(category_input)\n",
        "category_flatten = tf.keras.layers.Flatten()(category_embedding)\n",
        "\n",
        "# Input deskripsi\n",
        "description_input = tf.keras.layers.Input(shape=(max_sequence_length,), name='description_input')\n",
        "description_embedding = tf.keras.layers.Embedding(input_dim=vocab_size, output_dim=embedding_dim, name='description_embedding')(description_input)\n",
        "description_flatten = tf.keras.layers.GlobalAveragePooling1D()(description_embedding)\n",
        "\n",
        "# Gabungkan embedding\n",
        "concatenated = tf.keras.layers.Concatenate()([category_flatten, description_flatten])\n",
        "output = tf.keras.layers.Dense(embedding_dim, activation='relu')(concatenated)\n",
        "\n",
        "# Model\n",
        "model = tf.keras.Model(inputs=[category_input, description_input], outputs=output)\n",
        "model.compile(optimizer='adam', loss='mse')\n",
        "\n",
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E9Vnhrr8ZMBC",
        "outputId": "68a934b1-2bcf-40c4-80ac-e36f847fc3f7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                Output Shape                 Param #   Connected to                  \n",
            "==================================================================================================\n",
            " category_input (InputLayer  [(None, 1)]                  0         []                            \n",
            " )                                                                                                \n",
            "                                                                                                  \n",
            " description_input (InputLa  [(None, 65)]                 0         []                            \n",
            " yer)                                                                                             \n",
            "                                                                                                  \n",
            " category_embedding (Embedd  (None, 1, 50)                400       ['category_input[0][0]']      \n",
            " ing)                                                                                             \n",
            "                                                                                                  \n",
            " description_embedding (Emb  (None, 65, 50)               49450     ['description_input[0][0]']   \n",
            " edding)                                                                                          \n",
            "                                                                                                  \n",
            " flatten (Flatten)           (None, 50)                   0         ['category_embedding[0][0]']  \n",
            "                                                                                                  \n",
            " global_average_pooling1d (  (None, 50)                   0         ['description_embedding[0][0]'\n",
            " GlobalAveragePooling1D)                                            ]                             \n",
            "                                                                                                  \n",
            " concatenate (Concatenate)   (None, 100)                  0         ['flatten[0][0]',             \n",
            "                                                                     'global_average_pooling1d[0][\n",
            "                                                                    0]']                          \n",
            "                                                                                                  \n",
            " dense (Dense)               (None, 50)                   5050      ['concatenate[0][0]']         \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 54900 (214.45 KB)\n",
            "Trainable params: 54900 (214.45 KB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Melatih model dengan menggunakan input yang sama sebagai target (autoencoder)\n",
        "model.fit([X_category, X_description], model.predict([X_category, X_description]), epochs=10)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y-x38SBhZSIU",
        "outputId": "85ae89dc-bca7-4655-93e0-712fad8a88c0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "3/3 [==============================] - 1s 17ms/step\n",
            "Epoch 1/10\n",
            "3/3 [==============================] - 3s 391ms/step - loss: 2.5060e-17\n",
            "Epoch 2/10\n",
            "3/3 [==============================] - 1s 396ms/step - loss: 1.8330e-12\n",
            "Epoch 3/10\n",
            "3/3 [==============================] - 1s 277ms/step - loss: 3.9240e-09\n",
            "Epoch 4/10\n",
            "3/3 [==============================] - 1s 228ms/step - loss: 1.6389e-08\n",
            "Epoch 5/10\n",
            "3/3 [==============================] - 0s 143ms/step - loss: 2.6402e-08\n",
            "Epoch 6/10\n",
            "3/3 [==============================] - 1s 270ms/step - loss: 3.4136e-08\n",
            "Epoch 7/10\n",
            "3/3 [==============================] - 1s 248ms/step - loss: 2.5737e-08\n",
            "Epoch 8/10\n",
            "3/3 [==============================] - 1s 269ms/step - loss: 2.4621e-08\n",
            "Epoch 9/10\n",
            "3/3 [==============================] - 1s 337ms/step - loss: 2.1572e-08\n",
            "Epoch 10/10\n",
            "3/3 [==============================] - 1s 366ms/step - loss: 2.2455e-08\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.History at 0x7f5e16f77430>"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "\n",
        "# Mendapatkan embedding untuk semua tempat wisata\n",
        "embeddings = model.predict([X_category, X_description])\n",
        "\n",
        "# Fungsi untuk memberikan rekomendasi\n",
        "def recommend(place_id, embeddings, top_k=5):\n",
        "    place_idx = df.index[df['Place_Id'] == place_id].tolist()[0]\n",
        "    place_embedding = embeddings[place_idx]\n",
        "    similarities = cosine_similarity([place_embedding], embeddings)[0]\n",
        "    similar_indices = similarities.argsort()[::-1][1:top_k+1]\n",
        "    similar_places = df.iloc[similar_indices]['Place_Id'].values\n",
        "    return similar_places"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vqT8VHgyZVbV",
        "outputId": "e5895a0a-58a7-4aaf-a55f-c57b544088c2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "3/3 [==============================] - 0s 4ms/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Memuat data CSV untuk mapping prediction\n",
        "data = pd.read_csv('https://raw.githubusercontent.com/PenditWiguna/Capstone/main/Machine%20Learning/Dataset/Dataset%20-%20tourismBali.csv')\n",
        "df_convert = data[['Place_Id', 'Place_Name']]\n",
        "\n",
        "df2 = df_convert.set_index('Place_Id').to_dict()['Place_Name']"
      ],
      "metadata": {
        "id": "wHtaKCL-izo1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Contoh rekomendasi untuk tempat wisata dengan Place_Id\n",
        "place_id_predict = 23\n",
        "recommendations = recommend(place_id_predict, embeddings)\n",
        "place_record = []\n",
        "for i in recommendations:\n",
        "  place_record.append(df2[i])\n",
        "\n",
        "print(f\"Rekomendasi untuk Place_Id {place_id_predict}: {place_record}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0_BLXhRZbcxE",
        "outputId": "1d3b9b8f-8043-4d43-8598-4a2376bc64f3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Rekomendasi untuk Place_Id 23: ['Pura Taman Ayun', 'Tirta Gangga', 'Pura Puseh Batuan', 'Pura Besakih', 'Pura Saraswati']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Model Saving"
      ],
      "metadata": {
        "id": "-Dhd3A-TpkNX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Konversi model ke format TensorFlow Lite\n",
        "converter = tf.lite.TFLiteConverter.from_keras_model(model)\n",
        "tflite_model = converter.convert()\n",
        "\n",
        "# Simpan model ke file .tflite\n",
        "with open('recommender_model.tflite', 'wb') as f:\n",
        "    f.write(tflite_model)"
      ],
      "metadata": {
        "id": "-zEXqcC_pjBw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Vatiable Saving"
      ],
      "metadata": {
        "id": "_X3qKzY7dJws"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Data input untuk model\n",
        "X_category = df['Category_Encoded'].values\n",
        "X_description = padded_sequences\n",
        "\n",
        "# Gabungkan X_category dan X_description ke dalam satu DataFrame\n",
        "X_data = np.hstack((X_category.reshape(-1, 1), X_description))\n",
        "\n",
        "# Simpan ke file CSV\n",
        "np.savetxt('X_data.csv', X_data, delimiter=',', fmt='%d')"
      ],
      "metadata": {
        "id": "FKXtql58dMJS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Variable Testing"
      ],
      "metadata": {
        "id": "823MdBUFNY-I"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X_category"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mmEJX7fDNbtC",
        "outputId": "9fc696ca-f102-45db-ef8b-9ca20ca30227"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0, 2, 1, 1, 1, 1, 0, 4, 3, 6, 3, 0, 1, 0, 1, 1, 1, 3, 3, 3, 2, 3,\n",
              "       7, 1, 1, 7, 7, 0, 5, 2, 1, 2, 4, 3, 3, 5, 5, 5, 5, 5, 5, 5, 5, 5,\n",
              "       5, 5, 5, 5, 5, 5, 5, 7, 5, 5, 5, 2, 7, 7, 7, 7, 7, 7, 7, 5, 7, 7,\n",
              "       2, 1, 3, 3, 0, 7, 6, 0, 0])"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_description"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u73iYt4GNjZT",
        "outputId": "35cd2966-d1e6-4069-c1ff-96db38f64511"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[375, 376,  60, ...,   0,   0,   0],\n",
              "       [380,  30,  75, ...,   0,   0,   0],\n",
              "       [219,  12, 220, ...,   0,   0,   0],\n",
              "       ...,\n",
              "       [966,   9,  13, ...,   0,   0,   0],\n",
              "       [373, 374,   4, ...,   0,   0,   0],\n",
              "       [ 49,  73,  11, ...,   0,   0,   0]], dtype=int32)"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    }
  ]
}